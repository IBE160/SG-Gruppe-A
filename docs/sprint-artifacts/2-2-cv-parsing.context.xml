<story-context id="docs/sprint-artifacts/2-2-cv-parsing.context.xml" v="1.0">
  <metadata>
    <epicId>epic-2</epicId>
    <storyId>2.2</storyId>
    <title>CV Parsing</title>
    <status>drafted</status>
    <generatedAt>2025-12-06</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/sprint-artifacts/2-2-cv-parsing.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>developer</asA>
    <iWant>parse the uploaded CV file</iWant>
    <soThat>I can extract the text content for analysis</soThat>
    <tasks>
      - Task 1: CV Parsing Logic (AC: 1)
        - Subtask 1.1: Create a Python script or function within the Backend (e.g. app/services/cv_parser.py) to handle .docx parsing using python-docx.
        - Subtask 1.2: Implement text extraction logic that preserves basic structure (paragraphs) but removes formatting noise.
        - Subtask 1.3: Handle errors gracefully (e.g., unreadable files, password-protected files).
      - Task 2: Integration with Upload Flow (AC: 1)
        - Subtask 2.1: Integrate the parsing service into the CV Upload endpoint (POST /api/cv/upload).
        - Subtask 2.2: Ensure parsing happens asynchronously or efficiently after upload.
        - Subtask 2.3: Store the extracted text back into the CV table in PostgreSQL (extracted_text column).
      - Task 3: Testing (AC: 1)
        - Subtask 3.1: Unit test the parsing function with sample .docx files.
        - Subtask 3.2: Integration test the upload-and-parse flow.
        - Subtask 3.3: Verify that extracted text is correctly saved to the database.
    </tasks>
  </story>

  <acceptanceCriteria>
    1. Given a CV file has been uploaded, When the parsing process is triggered, Then the text content of the CV is extracted and stored.
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/sprint-artifacts/tech-spec-epic-2.md</path>
        <title>Epic Technical Specification: AI-Powered Generation &amp; Analysis</title>
        <section>Detailed Design</section>
        <snippet>Backend (Python/FastAPI): Responsibilities: CV parsing... Inputs: User's CV (text content from parsed .doc/.docx)... Dependencies: python-docx.</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Architecture Specification</title>
        <section>3.3. AI Service</section>
        <snippet>Core Functionality: CV Parsing: The service will use the python-docx library to parse .doc and .docx files uploaded by the user, extracting text content.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/2-1-cv-upload.md</path>
        <title>Story 2.1: CV Upload</title>
        <section>Dev Notes</section>
        <snippet>Backend: Python, FastAPI, PostgreSQL... Data Model: See tech-spec-epic-1.md for CV Model definition.</snippet>
      </doc>
      <doc>
        <path>docs/epics.md</path>
        <title>Epic Breakdown</title>
        <section>Story 2.2: CV Parsing</section>
        <snippet>As a developer, I want to parse the uploaded CV file... Technical Notes: Use a library like python-docx in the AI service to parse the CV content.</snippet>
      </doc>
    </docs>
    <code>
      <!-- No existing code artifacts for parsing logic yet -->
    </code>
    <dependencies>
      <dependency ecosystem="python">
        <package>python-docx</package>
        <package>fastapi</package>
        <package>pydantic</package>
      </dependency>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint>Backend: Python, FastAPI, python-docx</constraint>
    <constraint>Database: PostgreSQL (update 'extracted_text' column)</constraint>
    <constraint>Data Flow: Direct internal call or service invocation within FastAPI.</constraint>
  </constraints>

  <interfaces>
    <!-- No external interface for parsing as it's internal service logic now -->
  </interfaces>

  <tests>
    <standards>Verify extraction accuracy for standard CV layouts. Ensure robust error handling for malformed files.</standards>
    <locations>backend/python/tests/, backend/src/tests/integration/</locations>
    <ideas>
      <idea ac="1">Parse valid .docx -> Extracted text matches content</idea>
      <idea ac="1">Parse complex layout .docx -> Text order is preserved reasonably</idea>
      <idea ac="1">Parse corrupted file -> Returns 400/error, handles exception</idea>
      <idea ac="1">Integration: Node upload triggers Python parse -> DB updated with text</idea>
    </ideas>
  </tests>
</story-context>
