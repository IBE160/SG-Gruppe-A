<story-context id="docs/sprint-artifacts/2-2-cv-parsing.context.xml" v="1.0">
  <metadata>
    <epicId>epic-2</epicId>
    <storyId>2.2</storyId>
    <title>CV Parsing</title>
    <status>drafted</status>
    <generatedAt>2025-12-06</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/sprint-artifacts/2-2-cv-parsing.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>developer</asA>
    <iWant>parse the uploaded CV file</iWant>
    <soThat>I can extract the text content for analysis</soThat>
    <tasks>
      - Task 1: CV Parsing Logic (AC: 1)
        - Subtask 1.1: Create a Python script or function within the AI Service to handle .docx parsing using python-docx.
        - Subtask 1.2: Implement text extraction logic that preserves basic structure (paragraphs) but removes formatting noise.
        - Subtask 1.3: Handle errors gracefully (e.g., unreadable files, password-protected files).
      - Task 2: Integration with Upload Flow (AC: 1)
        - Subtask 2.1: Define a trigger mechanism (e.g., an API call from the Node.js backend to the Python AI Service, or a shared database polling/queue). Decision: Use a direct API call for the MVP (POST /ai/parse-cv).
        - Subtask 2.2: Implement the POST /ai/parse-cv endpoint in the FastAPI service.
        - Subtask 2.3: Update the Node.js backend to call this endpoint after successful file upload (from Story 2.1).
        - Subtask 2.4: Store the extracted text back into the CV table in PostgreSQL (extracted_text column).
      - Task 3: Testing (AC: 1)
        - Subtask 3.1: Unit test the Python parsing function with sample .docx files.
        - Subtask 3.2: Integration test the communication between Node.js backend and Python AI service.
        - Subtask 3.3: Verify that extracted text is correctly saved to the database.
    </tasks>
  </story>

  <acceptanceCriteria>
    1. Given a CV file has been uploaded, When the parsing process is triggered, Then the text content of the CV is extracted and stored.
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/sprint-artifacts/tech-spec-epic-2.md</path>
        <title>Epic Technical Specification: AI-Powered Generation &amp; Analysis</title>
        <section>Detailed Design</section>
        <snippet>AI Service (Python/FastAPI): Responsibilities: CV parsing... Inputs: User's CV (text content from parsed .doc/.docx)... Dependencies: python-docx.</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Architecture Specification</title>
        <section>3.3. AI Service</section>
        <snippet>Core Functionality: CV Parsing: The service will use the python-docx library to parse .doc and .docx files uploaded by the user, extracting text content.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/2-1-cv-upload.md</path>
        <title>Story 2.1: CV Upload</title>
        <section>Dev Notes</section>
        <snippet>Backend: Node.js, Express.js, PostgreSQL... Data Model: See tech-spec-epic-1.md for CV Model definition.</snippet>
      </doc>
      <doc>
        <path>docs/epics.md</path>
        <title>Epic Breakdown</title>
        <section>Story 2.2: CV Parsing</section>
        <snippet>As a developer, I want to parse the uploaded CV file... Technical Notes: Use a library like python-docx in the AI service to parse the CV content.</snippet>
      </doc>
    </docs>
    <code>
      <!-- No existing code artifacts for parsing logic yet -->
    </code>
    <dependencies>
      <dependency ecosystem="python">
        <package>python-docx</package>
        <package>fastapi</package>
        <package>pydantic</package>
      </dependency>
      <dependency ecosystem="javascript">
        <package>axios</package>
        <package>form-data</package>
      </dependency>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint>AI Service: Python, FastAPI, python-docx</constraint>
    <constraint>Backend: Node.js, Express.js (orchestrator)</constraint>
    <constraint>Communication: REST API (Node calls Python via POST /ai/parse-cv)</constraint>
    <constraint>Database: PostgreSQL (update 'extracted_text' column)</constraint>
    <constraint>Data Flow: Node backend streams file buffer/content to Python service to avoid shared volume complexity for MVP.</constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>Parse CV Endpoint</name>
      <kind>REST API</kind>
      <signature>POST /ai/parse-cv</signature>
      <path>docs/sprint-artifacts/2-2-cv-parsing.md</path>
    </interface>
  </interfaces>

  <tests>
    <standards>Verify extraction accuracy for standard CV layouts. Ensure robust error handling for malformed files.</standards>
    <locations>backend/python/tests/, backend/src/tests/integration/</locations>
    <ideas>
      <idea ac="1">Parse valid .docx -> Extracted text matches content</idea>
      <idea ac="1">Parse complex layout .docx -> Text order is preserved reasonably</idea>
      <idea ac="1">Parse corrupted file -> Returns 400/error, handles exception</idea>
      <idea ac="1">Integration: Node upload triggers Python parse -> DB updated with text</idea>
    </ideas>
  </tests>
</story-context>
