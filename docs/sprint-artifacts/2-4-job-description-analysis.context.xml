<story-context id="docs/sprint-artifacts/2-4-job-description-analysis.context.xml" v="1.0">
  <metadata>
    <epicId>epic-2</epicId>
    <storyId>2.4</storyId>
    <title>Job Description Analysis</title>
    <status>drafted</status>
    <generatedAt>2025-12-06</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/sprint-artifacts/2-4-job-description-analysis.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>developer</asA>
    <iWant>analyze the job description to identify key skills, qualifications, and keywords</iWant>
    <soThat>I can compare them with the user's CV</soThat>
    <tasks>
      - Task 1: AI Service JD Analysis Logic (AC: 1)
        - Subtask 1.1: Define the prompt template for the LLM to extract skills, qualifications, and keywords from a job description.
        - Subtask 1.2: Create a Pydantic model to structure the LLM output (e.g., class JobAnalysisResult(BaseModel): skills: list[str], qualifications: list[str], keywords: list[str]).
        - Subtask 1.3: Implement the analysis function in the Python AI Service using pydantic-ai and the Gemini model.
      - Task 2: Integration with JD Input Flow (AC: 1)
        - Subtask 2.1: Implement POST /ai/analyze-job-description endpoint (or service method) in the FastAPI service.
        - Subtask 2.2: Integrate the analysis call into the backend route (triggered by button).
        - Subtask 2.3: Store the analysis results (skills, keywords) in the JobDescription table (add JSONB column analysis_results) or a related table.
      - Task 3: Testing (AC: 1)
        - Subtask 3.1: Unit test the prompt and Pydantic model with sample JDs.
        - Subtask 3.2: Integration test the analysis flow.
        - Subtask 3.3: Verify the extracted data quality manually with a few real-world examples.
    </tasks>
  </story>

  <acceptanceCriteria>
    1. Given a job description has been submitted, When the analysis process is triggered, Then a list of key skills, qualifications, and keywords is extracted.
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/sprint-artifacts/tech-spec-epic-2.md</path>
        <title>Epic Technical Specification: AI-Powered Generation &amp; Analysis</title>
        <section>Detailed Design</section>
        <snippet>AI Service: Responsibilities: job description analysis... Inputs: Job Description (text)... Outputs: Missing Skills (list)...</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/2-3-job-description-input.md</path>
        <title>Story 2.3: Job Description Input</title>
        <section>Dev Notes</section>
        <snippet>Backend: Python, FastAPI. Database: PostgreSQL (JobDescription table).</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Architecture Specification</title>
        <section>3.3. AI Service</section>
        <snippet>AI Analysis &amp; Generation: It will interface with a third-party Large Language Model (LLM) API (e.g., GPT-4, Gemini) to perform... Extract keywords and requirements from a job description.</snippet>
      </doc>
      <doc>
        <path>docs/epics.md</path>
        <title>Epic Breakdown</title>
        <section>Story 2.4: Job Description Analysis</section>
        <snippet>As a developer, I want to analyze the job description... Technical Notes: Use an LLM in the AI service to analyze the job description.</snippet>
      </doc>
    </docs>
    <code>
      <!-- No existing code artifacts for JD analysis logic yet -->
    </code>
    <dependencies>
      <dependency ecosystem="python">
        <package>pydantic-ai</package>
        <package>google-generativeai</package>
        <package>fastapi</package>
      </dependency>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint>Backend: Python, FastAPI, Pydantic AI, Gemini 2.5</constraint>
    <constraint>Database: PostgreSQL (add JSONB column to JobDescription)</constraint>
    <constraint>Prompt Engineering: Need distinct lists for "skills", "qualifications", "keywords"</constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>Analyze Job Description Endpoint</name>
      <kind>REST API</kind>
      <signature>POST /ai/analyze-job-description</signature>
      <path>docs/sprint-artifacts/2-4-job-description-analysis.md</path>
    </interface>
  </interfaces>

  <tests>
    <standards>Focus on the structure of the returned JSON. The LLM might hallucinate, so validation of the format is more critical than 100% semantic accuracy for unit tests.</standards>
    <locations>backend/python/tests/, backend/src/tests/integration/</locations>
    <ideas>
      <idea ac="1">Analyze valid JD -> Returns structured JSON with skills, quals, keywords</idea>
      <idea ac="1">Analyze empty/short JD -> Returns empty lists or error</idea>
      <idea ac="1">Integration: Node calls Python -> DB updated with JSON result</idea>
    </ideas>
  </tests>
</story-context>
